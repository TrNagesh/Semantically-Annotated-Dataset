{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Finance.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"nJclutdfTGUP","colab_type":"code","colab":{}},"cell_type":"code","source":["## Reading Finance Based Papers"],"execution_count":0,"outputs":[]},{"metadata":{"id":"alogtqLdTLfB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"69336ef1-e2ca-4090-8315-5d43b7cb16d4","executionInfo":{"status":"ok","timestamp":1543727697202,"user_tz":-60,"elapsed":15199,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Read the finance papers from 2016 to 2018 and store it in a file\n","\n","import urllib\n","url = 'http://export.arxiv.org/oai2?verb=ListRecords&set=q-fin&from=2016-01-01&until=2018-11-31&metadataPrefix=arXiv' \n","data = urllib.request.urlopen(url).read()\n","\n","fin = open('finance1', 'wb')\n","fin.write(data)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1853006"]},"metadata":{"tags":[]},"execution_count":2}]},{"metadata":{"id":"hxx-pK2dTaPn","colab_type":"code","colab":{}},"cell_type":"code","source":["## Extract the title and abstract from papers - Read from finance1 to finance2\n","!xml_grep 'title|abstract' finance1  > finance2.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oj4B5h4ZTxEB","colab_type":"code","colab":{}},"cell_type":"code","source":["## Remove Junk lines , here we remove first 3 lines and last 3 lines which are not necessary\n","!cat finance2.txt | tail -n +4 | head -n -3 > finance3.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d0MnY4nXUI07","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"cd16fad3-f1e4-4456-c2c9-e78bfb66595a","executionInfo":{"status":"ok","timestamp":1543727770062,"user_tz":-60,"elapsed":2076,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Reading packages for Text classification\n","from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm \n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn import decomposition, ensemble\n","\n","import pandas, numpy, string\n","from keras.preprocessing import text, sequence\n","from keras import layers, models, optimizers\n","from nltk import word_tokenize\n","from nltk.corpus import stopwords\n","import sklearn\n","#import sklearn_crfsuite\n","#from sklearn_crfsuite import scorers\n","#from sklearn_crfsuite import metrics\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.metrics import accuracy_score\n","from sklearn import metrics"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"1yuRTT77USiK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"b04732da-3299-4b58-aa56-d7ad4521ca25","executionInfo":{"status":"ok","timestamp":1543727774008,"user_tz":-60,"elapsed":524,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Stopwords import and removal\n","import nltk\n","from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","stopwords = set(stopwords.words('english'))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"],"name":"stdout"}]},{"metadata":{"id":"F6iUlWK9UdRf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":128},"outputId":"f5cd162a-5b1f-4b3b-cb3f-5587b6770ace","executionInfo":{"status":"ok","timestamp":1543727781521,"user_tz":-60,"elapsed":695,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["# load the dataset # dataset contains combined labels and text from all training papers\n","data = open('labeled_sentences (1).txt').read()[:-2]\n","labels, texts = [], []\n","for i, line in enumerate(data.split(\"\\n\")):\n","    content = line.split()\n","    #print(content)\n","    labels.append(content[0])\n","    filtered_sentence = [w.lower() for w in content[1:] if not w in stopwords]\n","    texts.append(filtered_sentence)\n","\n","# create a dataframe using texts and lables\n","trainDF = pandas.DataFrame()\n","trainDF['text'] = texts\n","trainDF['label'] = labels\n","print(trainDF['label'].unique())\n","trainDF.head(2)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["['MISC' 'AIMX' 'OWNX' 'CONT' 'BASE']\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[minimum, description, length, principle, onli...</td>\n","      <td>MISC</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[underlying, model, class, discrete,, total, e...</td>\n","      <td>MISC</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text label\n","0  [minimum, description, length, principle, onli...  MISC\n","1  [underlying, model, class, discrete,, total, e...  MISC"]},"metadata":{"tags":[]},"execution_count":8}]},{"metadata":{"id":"6jlyRQouUdOq","colab_type":"code","colab":{}},"cell_type":"code","source":["## Used the obtained dataset for training\n","train_x, valid1_x, train_y, valid1_y = model_selection.train_test_split(trainDF['text'], trainDF['label'],test_size=0)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IP4zN8bMUvHL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"outputId":"e81b5632-15c5-494a-9f0b-31ea169aa854","executionInfo":{"status":"ok","timestamp":1543727789275,"user_tz":-60,"elapsed":533,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Convert from list to string\n","tempp = []\n","\n","for item in train_x:\n","    tempp.append(\" \".join(item))\n","#print(len(train_x))\n","\n","#tempp1 =[]\n","#for item1 in valid_x:\n","    #tempp1.append(\" \".join(item1))\n","    \n","#print(len(tempp1))\n","\n","temp =[]\n","temp_len=0\n","for item2 in texts:\n","    temp.append(\" \".join(item2))\n","    temp_len = temp_len+len(texts)\n","print(len(temp))\n","print(temp_len)\n","print(type(temp))\n"],"execution_count":10,"outputs":[{"output_type":"stream","text":["19162\n","367182244\n","<class 'list'>\n"],"name":"stdout"}]},{"metadata":{"id":"Gtg_YKrVUzBT","colab_type":"code","colab":{}},"cell_type":"code","source":["# create a count vectorizer object \n","count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n","count_vect.fit(temp)\n","\n","# transform the training and validation data using count vectorizer object\n","xtrain_count =  count_vect.transform(tempp)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uDvo_HNMU6wk","colab_type":"code","colab":{}},"cell_type":"code","source":["## Create a classifier\n","import csv\n","trainDF2 = pandas.DataFrame()  \n","\n","def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n","    # fit the training dataset on the classifier\n","    #std_clf = make_pipeline(StandardScaler(with_mean=False), TruncatedSVD(100), MultinominalNB())\n","    #std_clf.fit(feature_vector_train, label)\n","    classifier.fit(feature_vector_train, label)\n","    \n","    # predict the labels on validation dataset\n","    #predictions = classifier.predict(feature_vector_valid)\n","    predictions = classifier.predict(feature_vector_valid)\n","    return predictions\n","    #tt = classifier.predict(feature_vector_valid)\n","    #labels3 = classifier.predict(feature_vector_valid)\n","    \n","    #trainDF2['labels'] = labels3\n","    #trainDF2['text']= valid_x\n","    #print(trainDF2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k6RVdH0XVDpi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"fea13277-9abc-4cd6-d89e-22bd1cbd8d9e","executionInfo":{"status":"ok","timestamp":1543727819466,"user_tz":-60,"elapsed":556,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Read title and abstracts and loop through them \n","import re\n","global_list = []\n","title_list =[]\n","\n","test = open(\"finance3.txt\",'r').read().split(\"</abstract>\")\n","#print(test[1])\n","for idx,i in enumerate(test):\n","  title = re.findall(r\"(?<=<title>).*(?=</title>)\",i.replace(\"\\n\",\"\"))\n","  #print(title)\n","  abstract = re.findall(r\"(?<=<abstract>).*\",i.replace(\"\\n\",\"\"))\n","  #print(abstract[0].replace(\"\\n\",\"\"))\n","  nlist = re.split(r\"(?:(?<=[^i]\\.)|\\.(?=[^e]))\",abstract[0].replace('\"',\"\").replace('\\n',''))\n","  #temp_abs = re.sub(r\"((?<=[^i]\\.)|\\.(?=[^e]))\",\"\\n\",abstract[0])\n","  #print(abstract)\n","  #temp_str = temp_abs.split(\"\\n\")\n","  #print(temp_str[0])\n","  #print(nlist[1])\n","  global_list.append(nlist)\n","  title_list.append(title)\n","  #print(global_list)\n"," \n","  if idx >50:\n","    #print(global_list)\n","    break\n","  #print(abstract[0])\n","  #nlist = re.split(r\"(?:(?<=[^i]\\.)|\\.(?=[^e]))\",str(abstract))\n","  \n","  #print(nlist[1])\n","  \n","  #tempp1 =[]\n","  '''\n","  for idx, item1 in enumerate(nlist):\n","    \n","    if idx > 1 :\n","      break;\n","      print(item1)\n","      tempp1.append(\" \".join(item1))\n","    #print(tempp1)  \n","    \n","    xvalid_count =  count_vect.transform(tempp1)\n","    for item in nlist:\n","      print(item)\n","      valid_x = item\n","      #accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n","    \n","  '''\n","  #print(global_list[0])\n","  #print(global_list[1])\n","  #print(global_list[2])\n","  #for idx, item1 in enumerate(global_list) :\n","  #  if idx > 1:\n","  #    break\n","  #  print(item1)\n","    #tempp1.append(\" \".join(item1))\n","    #xvalid_count =  count_vect.transform(tempp1)\n","    #accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n","  "],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n","  return _compile(pattern, flags).split(string, maxsplit)\n"],"name":"stderr"}]},{"metadata":{"id":"ixCjHxOBVbrc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"outputId":"d75c6931-b02a-4eab-a02e-1382e72ce0af","executionInfo":{"status":"ok","timestamp":1543727831168,"user_tz":-60,"elapsed":5408,"user":{"displayName":"nagesh tr","photoUrl":"https://lh3.googleusercontent.com/-8yQwPUFPAaU/AAAAAAAAAAI/AAAAAAAAAJs/4cYlCbm-6q8/s64/photo.jpg","userId":"01347380177990762495"}}},"cell_type":"code","source":["## Print triples from data\n","\n","#print(global_list[1])\n","for idx, (item, title) in enumerate(zip(global_list, title_list)):\n","  \n","    \n","\n","  #print(item)\n","  valid_x = item\n","  xvalid_count =  count_vect.transform(valid_x)\n","  accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n","  #print(\"\\n\\n\")\n","  if idx>2:\n","    break\n","  \n","  title_id = hash(str(title))\n","  abstract_id = hash(str(item))\n","  line1 = \"<https://w3id.org/skg/articles/\" + str(title_id) + \"> <http://xmlns.com/foaf/0.1/name>\" + '\"' + \" \".join(title) + '\"' +\".\"\n","  line2 = \"<https://w3id.org/skg/articles/\" + str(title_id) + \"> <http://purl.org/dc/terms/abstract> <http://purl.org/dc/terms/abstract/\" + str(abstract_id)+ \">\"\n","  line3 = \"<https://w3id.org/skg/articles/\" + str(abstract_id) +\"><http://purl.org/dc/terms/abstract/text>\" + '\"' + \" \".join(item) + '\"'\n","  print(line1,line2,line3,sep =\"\\n\")\n","  for acc,element in zip(accuracy,item):\n","    print('<http://purl.org/dc/terms/abstract/{} > \"{}\"'.format(acc, element))  \n","    #line4 = (\"<http://purl.org/dc/terms/abstract/\" + str(acc) + \">\" + '\"' + str(element) + '\"' )\n","  "],"execution_count":14,"outputs":[{"output_type":"stream","text":["<https://w3id.org/skg/articles/-5159925132796795899> <http://xmlns.com/foaf/0.1/name>\"Average optimality for risk-sensitive control with general state space\".\n","<https://w3id.org/skg/articles/-5159925132796795899> <http://purl.org/dc/terms/abstract> <http://purl.org/dc/terms/abstract/8218326234501218954>\n","<https://w3id.org/skg/articles/8218326234501218954><http://purl.org/dc/terms/abstract/text>\"  This paper deals with discrete-time Markov control processes on a generalstate space  A long-run risk-sensitive average cost criterion is used as aperformance measure  The one-step cost function is nonnegative and possiblyunbounded  Using the vanishing discount factor approach, the optimalityinequality and an optimal stationary strategy for the decision maker areestablished.\"\n","<http://purl.org/dc/terms/abstract/AIMX > \"  This paper deals with discrete-time Markov control processes on a generalstate space\"\n","<http://purl.org/dc/terms/abstract/MISC > \" A long-run risk-sensitive average cost criterion is used as aperformance measure\"\n","<http://purl.org/dc/terms/abstract/MISC > \" The one-step cost function is nonnegative and possiblyunbounded\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" Using the vanishing discount factor approach, the optimalityinequality and an optimal stationary strategy for the decision maker areestablished.\"\n","<https://w3id.org/skg/articles/3516941775658297347> <http://xmlns.com/foaf/0.1/name>\"Maximum Entropy, the Collective Welfare Principle and the Globalization  Process\".\n","<https://w3id.org/skg/articles/3516941775658297347> <http://purl.org/dc/terms/abstract> <http://purl.org/dc/terms/abstract/6288511295907271878>\n","<https://w3id.org/skg/articles/6288511295907271878><http://purl.org/dc/terms/abstract/text>\"  Although both systems analyzed are described through two theories apparentlydifferent (quantum mechanics and game theory) it is shown that both areanalogous and thus exactly equivalents  The quantum analogue of the replicatordynamics is the von Neumann equation  Quantum mechanics could be used toexplain more correctly biological and economical processes  It could evenencloses theories like games and evolutionary dynamics  We can take someconcepts and definitions from quantum mechanics and physics for the bestunderstanding of the behavior of economics and biology  Also, we could maybeunderstand nature like a game in where its players compete for a common welfareand the equilibrium of the system that they are members  All the members of oursystem will play a game in which its maximum payoff is the equilibrium of thesystem  They act as a whole besides individuals like they obey a rule in wherethey prefer to work for the welfare of the collective besides the individualwelfare  A system where its members are in Nash Equilibrium (or ESS) is exactlyequivalent to a system in a maximum entropy state  A system is stable only ifit maximizes the welfare of the collective above the welfare of the individual If it is maximized the welfare of the individual above the welfare of thecollective the system gets unstable an eventually collapses  The results ofthis work shows that the globalization process has a behavior exactlyequivalent to a system that is tending to a maximum entropy state and predictsthe apparition of big common markets and strong common currencies that willfind its equilibrium by decreasing its number until they get a statecharacterized by only one common currency and only one common market around theworld.\"\n","<http://purl.org/dc/terms/abstract/MISC > \"  Although both systems analyzed are described through two theories apparentlydifferent (quantum mechanics and game theory) it is shown that both areanalogous and thus exactly equivalents\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" The quantum analogue of the replicatordynamics is the von Neumann equation\"\n","<http://purl.org/dc/terms/abstract/MISC > \" Quantum mechanics could be used toexplain more correctly biological and economical processes\"\n","<http://purl.org/dc/terms/abstract/MISC > \" It could evenencloses theories like games and evolutionary dynamics\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" We can take someconcepts and definitions from quantum mechanics and physics for the bestunderstanding of the behavior of economics and biology\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" Also, we could maybeunderstand nature like a game in where its players compete for a common welfareand the equilibrium of the system that they are members\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" All the members of oursystem will play a game in which its maximum payoff is the equilibrium of thesystem\"\n","<http://purl.org/dc/terms/abstract/BASE > \" They act as a whole besides individuals like they obey a rule in wherethey prefer to work for the welfare of the collective besides the individualwelfare\"\n","<http://purl.org/dc/terms/abstract/MISC > \" A system where its members are in Nash Equilibrium (or ESS) is exactlyequivalent to a system in a maximum entropy state\"\n","<http://purl.org/dc/terms/abstract/CONT > \" A system is stable only ifit maximizes the welfare of the collective above the welfare of the individual\"\n","<http://purl.org/dc/terms/abstract/OWNX > \"If it is maximized the welfare of the individual above the welfare of thecollective the system gets unstable an eventually collapses\"\n","<http://purl.org/dc/terms/abstract/MISC > \" The results ofthis work shows that the globalization process has a behavior exactlyequivalent to a system that is tending to a maximum entropy state and predictsthe apparition of big common markets and strong common currencies that willfind its equilibrium by decreasing its number until they get a statecharacterized by only one common currency and only one common market around theworld.\"\n","<https://w3id.org/skg/articles/2238203701590207870> <http://xmlns.com/foaf/0.1/name>\"On the Structure of General Mean-Variance Hedging Strategies\".\n","<https://w3id.org/skg/articles/2238203701590207870> <http://purl.org/dc/terms/abstract> <http://purl.org/dc/terms/abstract/-6562757750981027048>\n","<https://w3id.org/skg/articles/-6562757750981027048><http://purl.org/dc/terms/abstract/text>\"  We provide a new characterization of mean-variance hedging strategies in ageneral semimartingale market  The key point is the introduction of a newprobability measure $P^{\\star}$ which turns the dynamic asset allocationproblem into a myopic one  The minimal martingale measure relative to$P^{\\star}$ coincides with the variance-optimal martingale measure relative tothe original probability measure $P$.\"\n","<http://purl.org/dc/terms/abstract/OWNX > \"  We provide a new characterization of mean-variance hedging strategies in ageneral semimartingale market\"\n","<http://purl.org/dc/terms/abstract/MISC > \" The key point is the introduction of a newprobability measure $P^{\\star}$ which turns the dynamic asset allocationproblem into a myopic one\"\n","<http://purl.org/dc/terms/abstract/OWNX > \" The minimal martingale measure relative to$P^{\\star}$ coincides with the variance-optimal martingale measure relative tothe original probability measure $P$.\"\n"],"name":"stdout"}]}]}